{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9911bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DenseNet121 N_FFT 256 - 23 EPOCHS - 0.96 ACC ON 20% TEST\n",
    "import os, math\n",
    "import numpy as np\n",
    "seed = 2018\n",
    "np.random.seed(seed)\n",
    "\n",
    "import librosa\n",
    "from scipy import signal\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchvision.models import densenet121\n",
    "import torch\n",
    "import torch.nn as nn; import torch.nn.functional as F\n",
    "import torch.optim as optim; from torch.optim import lr_scheduler\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from keras.layers import Input\n",
    "\n",
    "#from keras.callbacks import ModelCheckpoint\n",
    "#from keras.callbacks import EarlyStopping\n",
    "#from keras.callbacks import ReduceLROnPlateau\n",
    "#from keras.callbacks import CSVLogger\n",
    "\n",
    "#from keras import Model\n",
    "#from keras import backend as K\n",
    "\n",
    "#from keras.utils import np_utils\n",
    "#from keras.preprocessing import image\n",
    " \n",
    "#from keras.applications.densenet import DenseNet121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbe78892",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = densenet121\n",
    "\n",
    "\n",
    "model_name = 'wingbeats_' + current_model.__name__\n",
    "\n",
    "best_weights_path = model_name + '.h5'\n",
    "log_path = model_name + '.log'\n",
    "monitor = 'val_acc'\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "es_patience = 7\n",
    "rlr_patience = 3\n",
    "\n",
    "SR = 8000\n",
    "N_FFT = 256\n",
    "HOP_LEN = N_FFT / 6\n",
    "input_shape = (129, 120, 1)\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f13c1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ae. aegypti #recs =  85553\n",
      "Ae. albopictus #recs =  20231\n",
      "An. gambiae #recs =  49471\n",
      "An. arabiensis #recs =  19297\n",
      "C. pipiens #recs =  30415\n",
      "C. quinquefasciatus #recs =  74599\n",
      "total #recs =  279566\n",
      "train #recs =  223652\n",
      "test #recs =  55914\n",
      "Total :  279566\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Ae. aegypti', 'Ae. albopictus', 'An. gambiae', 'An. arabiensis', 'C. pipiens', 'C. quinquefasciatus']\n",
    "\n",
    "X_names = []\n",
    "y = []\n",
    "target_count = []\n",
    "\n",
    "for i, target in enumerate(target_names):\n",
    "    target_count.append(0)\n",
    "    path = './../Wingbeats/' + target + '/'\n",
    "    for [root, dirs, files] in os.walk(path, topdown = False):\n",
    "        for filename in files:\n",
    "            name,ext = os.path.splitext(filename)\n",
    "            if ext == '.wav':\n",
    "                name = os.path.join(root, filename)\n",
    "                y.append(i)\n",
    "                X_names.append(name)\n",
    "                target_count[i]+=1\n",
    "                # if target_count[i] > 20000:\n",
    "                #     break\n",
    "    print (target, '#recs = ', target_count[i])\n",
    "\n",
    "print ('total #recs = ', len(y))\n",
    "\n",
    "X_names, y = shuffle(X_names, y, random_state = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_names, y, stratify = y, test_size = 0.20, random_state = seed)\n",
    "\n",
    "print('train #recs = ', len(X_train))\n",
    "print('test #recs = ', len(X_test))\n",
    "print('Total : ', len(X_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ee36627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift(x, wshift, hshift):\n",
    "    \n",
    "    original_shape = x.shape\n",
    "    if len(original_shape) == 3:\n",
    "        x = x.unsqueeze(0)\n",
    "    \n",
    "    b, c, h, w = x.shape\n",
    "    \n",
    "    tx = hshift * h\n",
    "    ty = wshift * w\n",
    "    \n",
    "    theta = torch.tensor([[\n",
    "        [1.0, 0.0, ty],\n",
    "        [0.0, 1.0, tx]\n",
    "    ]], dtype=torch.float32).repeat(b, 1, 1)\n",
    "    \n",
    "    grid = F.affine_grid(theta, x.size(), align_corners=False)\n",
    "    x_transformed = F.grid_sample(x, grid, mode='bilinear', padding_mode='zeros', align_corners=False)\n",
    "    \n",
    "    if len(original_shape) == 3:\n",
    "        x_transformed = x_transformed.squeeze(0)\n",
    "    \n",
    "    return x_transformed\n",
    "\n",
    "def random_data_shift(data, w_limit = (-0.25, 0.25), h_limit = (-0.0, 0.0), cval = 0., u = 0.5):\n",
    "    if np.random.random() < u:\n",
    "        wshift = np.random.uniform(w_limit[0], w_limit[1])\n",
    "        hshift = np.random.uniform(h_limit[0], h_limit[1])\n",
    "        data = shift(data, wshift, hshift, cval = cval)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a422478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    while True:\n",
    "        for start in range(0, len(X_train), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            \n",
    "            end = min(start + batch_size, len(X_train))\n",
    "            train_batch = X_train[start:end]\n",
    "            labels_batch = y_train[start:end]\n",
    "            \n",
    "            for i in range(len(train_batch)):\n",
    "                data, _ = librosa.load(train_batch[i], sr = SR)\n",
    "\n",
    "                data = librosa.stft(data, n_fft = N_FFT, hop_length = HOP_LEN)\n",
    "                data = librosa.amplitude_to_db(data)\n",
    "\n",
    "                data = np.flipud(data)\n",
    "\n",
    "                data = np.expand_dims(data, axis = -1)\n",
    "                data = random_data_shift(data, w_limit = (-0.25, 0.25), h_limit = (-0.0, 0.0), cval = np.min(data), u = 1.0)\n",
    "\n",
    "                # data = np.squeeze(data, axis = -1)\n",
    "                # plt.imshow(data, cmap = 'gray')\n",
    "                # plt.show()\n",
    "                # data = np.expand_dims(data, axis = -1)\n",
    "\n",
    "                x_batch.append(data)\n",
    "                y_batch.append(labels_batch[i])\n",
    "\n",
    "            x_batch = np.array(x_batch, np.float32)\n",
    "            y_batch = np.array(y_batch, np.float32)\n",
    "            \n",
    "            y_batch = F.one_hot(y_batch, len(target_names))\n",
    "            \n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift(x, wshift, hshift, row_axis=0, col_axis=1, channel_axis=2, fill_mode='constant', cval=0.):\n",
    "    if not isinstance(x, torch.Tensor):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "    \n",
    "    original_shape = x.shape\n",
    "    is_batch = len(original_shape) == 4\n",
    "    \n",
    "    # Añadir dimensión de batch si es necesario\n",
    "    if len(original_shape) == 3:\n",
    "        x = x.unsqueeze(0)\n",
    "    \n",
    "    # Obtener dimensiones (asumiendo formato PyTorch: B, C, H, W)\n",
    "    b, c, h, w = x.shape\n",
    "    \n",
    "    # Calcular desplazamientos en píxeles (nota: en PyTorch el orden es diferente)\n",
    "    tx = hshift * h  # desplazamiento vertical\n",
    "    ty = wshift * w  # desplazamiento horizontal\n",
    "    \n",
    "    # Matriz de transformación afín 2x3 para PyTorch\n",
    "    theta = torch.tensor([[\n",
    "        [1.0, 0.0, ty],  # Atención: ty va primero para horizontal\n",
    "        [0.0, 1.0, tx]   # tx para vertical\n",
    "    ]], dtype=torch.float32).repeat(b, 1, 1)\n",
    "    \n",
    "    # Crear grid de transformación\n",
    "    grid = F.affine_grid(theta, x.size(), align_corners=False)\n",
    "    \n",
    "    # Mapear modos de relleno\n",
    "    padding_mode = 'zeros'\n",
    "    if fill_mode == 'reflect':\n",
    "        padding_mode = 'reflection'\n",
    "    elif fill_mode == 'nearest':\n",
    "        padding_mode = 'border'\n",
    "    \n",
    "    # Aplicar transformación\n",
    "    x_transformed = F.grid_sample(x, grid, mode='bilinear', padding_mode=padding_mode, align_corners=False)\n",
    "    \n",
    "    # Manejar valor constante personalizado\n",
    "    if fill_mode == 'constant' and cval != 0:\n",
    "        # Detectar áreas fuera de los límites\n",
    "        mask = (grid >= -1) & (grid <= 1)\n",
    "        mask = mask.all(dim=-1, keepdim=True)\n",
    "        mask = mask.repeat(1, 1, 1, c).permute(0, 3, 1, 2)\n",
    "        x_transformed = torch.where(mask, x_transformed, torch.tensor(cval, dtype=x.dtype))\n",
    "    \n",
    "    # Recuperar forma original\n",
    "    if not is_batch:\n",
    "        x_transformed = x_transformed.squeeze(0)\n",
    "    \n",
    "    return x_transformed\n",
    "\n",
    "def random_data_shift(data, w_limit=(-0.25, 0.25), h_limit=(-0.0, 0.0), cval=0., u=0.5):\n",
    "    \"\"\"Versión PyTorch de random_data_shift\"\"\"\n",
    "    if np.random.random() < u:\n",
    "        wshift = np.random.uniform(w_limit[0], w_limit[1])\n",
    "        hshift = np.random.uniform(h_limit[0], h_limit[1])\n",
    "        data = shift(data, wshift, hshift, cval=cval)\n",
    "    return data\n",
    "\n",
    "# Dataset personalizado para PyTorch\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, target_names, sr=22050, n_fft=2048, hop_len=512):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.target_names = target_names\n",
    "        self.sr = sr\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_len = hop_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Cargar audio\n",
    "        data, _ = librosa.load(self.file_paths[idx], sr=self.sr)\n",
    "        \n",
    "        # Convertir a espectrograma\n",
    "        data = librosa.stft(data, n_fft=self.n_fft, hop_length=self.hop_len)\n",
    "        data = librosa.amplitude_to_db(data)\n",
    "        data = np.flipud(data)  # Voltear verticalmente\n",
    "        \n",
    "        # Convertir a tensor PyTorch (C, H, W)\n",
    "        data = torch.tensor(data, dtype=torch.float32)\n",
    "        data = data.unsqueeze(0)  # Añadir canal: (1, H, W)\n",
    "        \n",
    "        # Aplicar aumento de datos (siempre en este caso, u=1.0)\n",
    "        data = random_data_shift(data, \n",
    "                               w_limit=(-0.25, 0.25), \n",
    "                               h_limit=(-0.0, 0.0), \n",
    "                               cval=float(data.min()), \n",
    "                               u=1.0)\n",
    "        \n",
    "        # Etiqueta\n",
    "        label = self.labels[idx]\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return data, label_tensor\n",
    "\n",
    "# Función para crear el DataLoader\n",
    "def create_loader(X_train, y_train, target_names, batch_size=32, sr=22050, n_fft=2048, hop_len=512, shuffle=True):\n",
    "    dataset = AudioDataset(X_train, y_train, target_names, sr, n_fft, hop_len)\n",
    "    \n",
    "    # Función de collate personalizada para manejar las etiquetas categóricas\n",
    "    def collate_fn(batch):\n",
    "        data_list, label_list = [], []\n",
    "        for data, label in batch:\n",
    "            data_list.append(data)\n",
    "            label_list.append(label)\n",
    "        \n",
    "        # Apilar datos\n",
    "        data_batch = torch.stack(data_list)\n",
    "        \n",
    "        # Convertir etiquetas a one-hot encoding\n",
    "        labels_batch = torch.stack(label_list)\n",
    "        labels_one_hot = torch.nn.functional.one_hot(labels_batch, num_classes=len(target_names)).float()\n",
    "        \n",
    "        return data_batch, labels_one_hot\n",
    "    \n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
    "    return loader\n",
    "\n",
    "# Uso ejemplo:\n",
    "# train_loader = create_train_loader(X_train, y_train, target_names, batch_size=32)\n",
    "\n",
    "# En tu loop de entrenamiento:\n",
    "# for epoch in range(epochs):\n",
    "#     for x_batch, y_batch in train_loader:\n",
    "#         # x_batch: (batch_size, 1, height, width)\n",
    "#         # y_batch: (batch_size, num_classes) one-hot encoded\n",
    "#         # ... tu código de entrenamiento ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a6759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_generator():\n",
    "    while True:\n",
    "        for start in range(0, len(X_test), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            \n",
    "            end = min(start + batch_size, len(X_test))\n",
    "            test_batch = X_test[start:end]\n",
    "            labels_batch = y_test[start:end]\n",
    "            \n",
    "            for i in range(len(test_batch)):\n",
    "                data, rate = librosa.load(test_batch[i], sr = SR)\n",
    "\n",
    "                data = librosa.stft(data, n_fft = N_FFT, hop_length = HOP_LEN)\n",
    "                data = librosa.amplitude_to_db(data)\n",
    "\n",
    "                data = np.flipud(data)\n",
    "\n",
    "                data = np.expand_dims(data, axis = -1)\n",
    "\n",
    "                x_batch.append(data)\n",
    "                y_batch.append(labels_batch[i])\n",
    "\n",
    "            x_batch = np.array(x_batch, np.float32)\n",
    "            y_batch = np.array(y_batch, np.float32)\n",
    "            \n",
    "            y_batch = F.one_hot.to_categorical(y_batch, len(target_names))\n",
    "            \n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76afd03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = current_model(weights=None)\n",
    "model_ft.features.conv0 = nn.Conv2d(1, 64, \n",
    "                                     kernel_size=7, \n",
    "                                     stride=2, \n",
    "                                     padding=3, \n",
    "                                     bias=False)\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "model_ft.classifier = nn.Linear(num_ftrs, 6)\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3205e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = Input(shape = input_shape)\n",
    "\n",
    "model = current_model(input_tensor = img_input, classes = len(target_names), weights = None)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])  \n",
    "\n",
    "callbacks_list = [ModelCheckpoint(monitor = monitor,\n",
    "                                filepath = best_weights_path, \n",
    "                                save_best_only = True, \n",
    "                                save_weights_only = True,\n",
    "                                verbose = 1), \n",
    "                    EarlyStopping(monitor = monitor,\n",
    "                                patience = es_patience, \n",
    "                                verbose = 1),\n",
    "                    ReduceLROnPlateau(monitor = monitor,\n",
    "                                factor = 0.1, \n",
    "                                patience = rlr_patience, \n",
    "                                verbose = 1),\n",
    "                    CSVLogger(filename = log_path)]\n",
    "\n",
    "model.fit_generator(train_generator(),\n",
    "    steps_per_epoch = int(math.ceil(float(len(X_train)) / float(batch_size))),\n",
    "    validation_data = valid_generator(),\n",
    "    validation_steps = int(math.ceil(float(len(X_test)) / float(batch_size))),\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks_list,\n",
    "    shuffle = False)\n",
    "\n",
    "model.load_weights(best_weights_path)\n",
    "\n",
    "loss, acc = model.evaluate_generator(valid_generator(),\n",
    "        steps = int(math.ceil(float(len(X_test)) / float(batch_size))))\n",
    "\n",
    "#print('loss:', loss)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosquitosClasificacion (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
