{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9911bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DenseNet121 N_FFT 256 - 23 EPOCHS - 0.96 ACC ON 20% TEST\n",
    "import os, math\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import librosa\n",
    "from scipy import signal\n",
    "\n",
    "import tqdm \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchvision.models import densenet121\n",
    "import torch\n",
    "import torch.nn as nn; import torch.nn.functional as F\n",
    "import torch.optim as optim; from torch.optim import lr_scheduler\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#from keras.layers import Input\n",
    "\n",
    "#from keras.callbacks import ModelCheckpoint\n",
    "#from keras.callbacks import EarlyStopping\n",
    "#from keras.callbacks import ReduceLROnPlateau\n",
    "#from keras.callbacks import CSVLogger\n",
    "\n",
    "#from keras import Model\n",
    "#from keras import backend as K\n",
    "\n",
    "#from keras.utils import np_utils\n",
    "#from keras.preprocessing import image\n",
    " \n",
    "#from keras.applications.densenet import DenseNet121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe78892",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = densenet121\n",
    "\n",
    "\n",
    "model_name = 'wingbeats_' + current_model.__name__\n",
    "\n",
    "best_weights_path = model_name + '.pt'\n",
    "log_path = model_name + '.log'\n",
    "monitor = 'val_acc'\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "es_patience = 7\n",
    "rlr_patience = 3\n",
    "\n",
    "SR = 8000\n",
    "N_FFT = 256\n",
    "HOP_LEN = N_FFT // 6\n",
    "input_shape = (129, 120, 1)\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available else 'cpu'\n",
    "seed = 2018\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f13c1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ae. aegypti #recs =  85553\n",
      "Ae. albopictus #recs =  20231\n",
      "An. gambiae #recs =  49471\n",
      "An. arabiensis #recs =  19297\n",
      "C. pipiens #recs =  30415\n",
      "C. quinquefasciatus #recs =  74599\n",
      "total #recs =  279566\n",
      "train #recs =  223652\n",
      "test #recs =  55914\n",
      "Total :  279566\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Ae. aegypti', 'Ae. albopictus', 'An. gambiae', 'An. arabiensis', 'C. pipiens', 'C. quinquefasciatus']\n",
    "\n",
    "X_names = []\n",
    "y = []\n",
    "target_count = []\n",
    "\n",
    "for i, target in enumerate(target_names):\n",
    "    target_count.append(0)\n",
    "    path = './../Wingbeats/' + target + '/'\n",
    "    for [root, dirs, files] in os.walk(path, topdown = False):\n",
    "        for filename in files:\n",
    "            name,ext = os.path.splitext(filename)\n",
    "            if ext == '.wav':\n",
    "                name = os.path.join(root, filename)\n",
    "                y.append(i)\n",
    "                X_names.append(name)\n",
    "                target_count[i]+=1\n",
    "                # if target_count[i] > 20000:\n",
    "                #     break\n",
    "    print (target, '#recs = ', target_count[i])\n",
    "\n",
    "print ('total #recs = ', len(y))\n",
    "\n",
    "X_names, y = shuffle(X_names, y, random_state = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_names, y, stratify = y, test_size = 0.20, random_state = seed)\n",
    "\n",
    "n_samples = len(X_train)\n",
    "n_tests = len(X_test)\n",
    "print('train #recs = ', len(X_train))\n",
    "print('test #recs = ', len(X_test))\n",
    "print('Total : ', len(X_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a66e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift(x, wshift, hshift, row_axis=1, col_axis=2, channel_axis=0, fill_mode='constant', cval=0.):\n",
    "    \"\"\"\n",
    "    Versión corregida de la función shift para PyTorch\n",
    "    \"\"\"\n",
    "    # Asegurar que el tensor es 4D (batch, channels, height, width)\n",
    "    if x.dim() == 3:\n",
    "        # Si es (C, H, W), añadir dimensión batch\n",
    "        x = x.unsqueeze(0)\n",
    "        was_3d = True\n",
    "    else:\n",
    "        was_3d = False\n",
    "    \n",
    "    # Obtener dimensiones\n",
    "    batch_size, channels, h, w = x.shape\n",
    "    \n",
    "    # Calcular desplazamiento en píxeles\n",
    "    tx = hshift * h  # Desplazamiento vertical\n",
    "    ty = wshift * w  # Desplazamiento horizontal\n",
    "    \n",
    "    # Crear matriz de transformación para PyTorch (2x3)\n",
    "    theta = torch.tensor([\n",
    "        [1, 0, ty],  # Transformación en X (ancho)\n",
    "        [0, 1, tx]   # Transformación en Y (alto)\n",
    "    ], dtype=torch.float32)\n",
    "    \n",
    "    # Repetir para todo el batch\n",
    "    theta = theta.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    \n",
    "    # Mover al mismo dispositivo que x\n",
    "    theta = theta.to(x.device)\n",
    "    \n",
    "    # Crear grid de transformación (necesita tamaño 4D)\n",
    "    grid = F.affine_grid(theta, x.size(), align_corners=False)\n",
    "    \n",
    "    # Mapear modos de relleno\n",
    "    padding_mode = 'zeros' if fill_mode == 'constant' else fill_mode\n",
    "    \n",
    "    # Aplicar la transformación\n",
    "    x = F.grid_sample(x, grid, mode='bilinear', padding_mode=padding_mode, align_corners=False)\n",
    "    \n",
    "    # Remover dimensión batch si originalmente era 3D\n",
    "    if was_3d:\n",
    "        x = x.squeeze(0)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def random_data_shift(data, w_limit=(-0.25, 0.25), h_limit=(-0.0, 0.0), cval=0., u=0.5):\n",
    "    \"\"\"Versión corregida de random_data_shift\"\"\"\n",
    "    if torch.rand(1) < u:\n",
    "        wshift = torch.empty(1).uniform_(w_limit[0], w_limit[1]).item()\n",
    "        hshift = torch.empty(1).uniform_(h_limit[0], h_limit[1]).item()\n",
    "        data = shift(data, wshift, hshift, cval=cval)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffeb830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, target_names, sr=22050, n_fft=2048, hop_len=512):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.target_names = target_names\n",
    "        self.sr = sr\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_len = hop_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data, _ = librosa.load(self.file_paths[idx], sr=self.sr)\n",
    "        \n",
    "        data = librosa.stft(data, n_fft=self.n_fft, hop_length=self.hop_len)\n",
    "        data = librosa.amplitude_to_db(np.abs(data))\n",
    "        data = np.flipud(data)  # Voltear verticalmente\n",
    "        data = data.copy()\n",
    "        data = torch.tensor(data, dtype=torch.float32)\n",
    "        data = data.unsqueeze(0)  # Añadir canal: (1, H, W)\n",
    "        \n",
    "        data = random_data_shift(data, \n",
    "                               w_limit=(-0.25, 0.25), \n",
    "                               h_limit=(-0.0, 0.0), \n",
    "                               cval=float(data.min()), \n",
    "                               u=1.0)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return data, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5048c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loader(X_train, y_train, target_names, batch_size=32, sr=22050, n_fft=2048, hop_len=512, shuffle=True):\n",
    "    dataset = AudioDataset(X_train, y_train, target_names, sr, n_fft, hop_len)\n",
    "    \n",
    "    def collate_fn(batch):\n",
    "        data_list, label_list = [], []\n",
    "        for data, label in batch:\n",
    "            data_list.append(data)\n",
    "            label_list.append(label)\n",
    "        \n",
    "        data_batch = torch.stack(data_list)\n",
    "        \n",
    "        labels_batch = torch.stack(label_list)\n",
    "        labels_one_hot = torch.nn.functional.one_hot(labels_batch, num_classes=len(target_names)).float()\n",
    "        \n",
    "        return data_batch, labels_one_hot\n",
    "    \n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d7d8802",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = create_loader(X_train, y_train, target_names, batch_size=batch_size,\n",
    "                        sr=SR, n_fft=N_FFT, hop_len=HOP_LEN, shuffle=True)\n",
    "test_dataloader = create_loader(X_test, y_test, target_names, batch_size=batch_size,\n",
    "                        sr=SR, n_fft=N_FFT, hop_len=HOP_LEN, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d0667d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model_for_audio(current_model, num_classes, input_channels=1):\n",
    "    \"\"\"\n",
    "    Configura automáticamente el modelo para espectrogramas de audio\n",
    "    \"\"\"\n",
    "    model = current_model(num_classes=num_classes)\n",
    "    \n",
    "    # Detectar si el modelo es de torchvision y necesita ajuste de canales\n",
    "    model_name = model.__class__.__name__.lower()\n",
    "    \n",
    "    # Lista de modelos que normalmente esperan 3 canales\n",
    "    rgb_models = ['resnet', 'densenet', 'alexnet', 'vgg', 'mobilenet', 'inception']\n",
    "    \n",
    "    needs_channel_adjustment = any(rgb_model in model_name for rgb_model in rgb_models)\n",
    "    \n",
    "    if needs_channel_adjustment:\n",
    "        print(f\"Ajustando {model_name} para {input_channels} canal(es) de entrada\")\n",
    "        model = adjust_first_conv_layer(model, input_channels)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def adjust_first_conv_layer(model, input_channels):\n",
    "    \"\"\"\n",
    "    Ajusta la primera capa convolucional para aceptar input_channels\n",
    "    \"\"\"\n",
    "    if hasattr(model, 'conv1'):\n",
    "        # Para modelos como ResNet\n",
    "        original_conv = model.conv1\n",
    "        model.conv1 = nn.Conv2d(\n",
    "            input_channels, \n",
    "            original_conv.out_channels,\n",
    "            kernel_size=original_conv.kernel_size,\n",
    "            stride=original_conv.stride,\n",
    "            padding=original_conv.padding,\n",
    "            bias=original_conv.bias is not None\n",
    "        )\n",
    "    elif hasattr(model, 'features') and hasattr(model.features, 'conv0'):\n",
    "        # Para DenseNet\n",
    "        original_conv = model.features.conv0\n",
    "        model.features.conv0 = nn.Conv2d(\n",
    "            input_channels,\n",
    "            original_conv.out_channels,\n",
    "            kernel_size=original_conv.kernel_size,\n",
    "            stride=original_conv.stride,\n",
    "            padding=original_conv.padding,\n",
    "            bias=original_conv.bias is not None\n",
    "        )\n",
    "    elif hasattr(model, 'features') and len(model.features) > 0:\n",
    "        # Para VGG, AlexNet, etc.\n",
    "        first_conv = model.features[0]\n",
    "        if isinstance(first_conv, nn.Conv2d):\n",
    "            model.features[0] = nn.Conv2d(\n",
    "                input_channels,\n",
    "                first_conv.out_channels,\n",
    "                kernel_size=first_conv.kernel_size,\n",
    "                stride=first_conv.stride,\n",
    "                padding=first_conv.padding,\n",
    "                bias=first_conv.bias is not None\n",
    "            )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76afd03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajustando densenet para 1 canal(es) de entrada\n"
     ]
    }
   ],
   "source": [
    "model = setup_model_for_audio(current_model, len(target_names), input_channels=1)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max',\n",
    "    factor=0.1, \n",
    "    patience=rlr_patience\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbf13ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchCallbacks:\n",
    "    def __init__(self, model, best_weights_path, log_path, monitor='val_loss', patience=10):\n",
    "        self.model = model\n",
    "        self.best_weights_path = best_weights_path\n",
    "        self.log_path = log_path\n",
    "        self.monitor = monitor\n",
    "        self.patience = patience\n",
    "        \n",
    "        self.best_metric = float('inf') if monitor == 'val_loss' else 0\n",
    "        self.epochs_no_improve = 0\n",
    "        self.writer = SummaryWriter()  # Para logging (opcional)\n",
    "        \n",
    "        # Crear directorios si no existen\n",
    "        #os.makedirs(os.path.dirname(best_weights_path), exist_ok=True)\n",
    "        #os.makedirs(os.path.dirname(log_path), exist_ok=True)\n",
    "\n",
    "    def on_epoch_end(self, current_metric, epoch):\n",
    "        improved = False\n",
    "        \n",
    "        if self.monitor == 'val_loss' and current_metric < self.best_metric:\n",
    "            improved = True\n",
    "        elif self.monitor == 'val_accuracy' and current_metric > self.best_metric:\n",
    "            improved = True\n",
    "        \n",
    "        if improved:\n",
    "            print(f\"\\nMétrica mejorada de {self.best_metric:.4f} a {current_metric:.4f}\")\n",
    "            self.best_metric = current_metric\n",
    "            self.epochs_no_improve = 0\n",
    "            \n",
    "            # Guardar mejores pesos (ModelCheckpoint)\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': self.model.state_dict(),\n",
    "                'best_metric': self.best_metric\n",
    "            }, self.best_weights_path)\n",
    "            print(f\"Pesos guardados en {self.best_weights_path}\")\n",
    "        else:\n",
    "            self.epochs_no_improve += 1\n",
    "    \n",
    "    def should_stop(self):\n",
    "        if self.epochs_no_improve >= self.patience:\n",
    "            print(f\"\\nEarlyStopping: No mejora después de {self.patience} épocas\")\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def log_metrics(self, epoch, train_loss, val_loss, train_acc, val_acc):\n",
    "        log_entry = f\"{epoch},{train_loss:.4f},{val_loss:.4f},{train_acc:.4f},{val_acc:.4f}\\n\"\n",
    "        \n",
    "        with open(self.log_path, 'a') as f:\n",
    "            if epoch == 0:\n",
    "                f.write(\"epoch,train_loss,val_loss,train_accuracy,val_accuracy\\n\")\n",
    "            f.write(log_entry)\n",
    "        \n",
    "        self.writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        self.writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "        self.writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "        self.writer.add_scalar('Accuracy/val', val_acc, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed902614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        # CONVERTIR ONE-HOT A ÍNDICES\n",
    "        if target.dim() > 1 and target.shape[1] > 1:\n",
    "            target = target.argmax(dim=1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    return total_loss / len(dataloader), correct / total\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            if torch.cuda.is_available():\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            # CONVERTIR ONE-HOT A ÍNDICES\n",
    "            if target.dim() > 1 and target.shape[1] > 1:\n",
    "                target = target.argmax(dim=1)\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    return total_loss / len(dataloader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5493c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EarlyStopping: No mejora después de 7 épocas\n"
     ]
    }
   ],
   "source": [
    "# Inicializar callbacks\n",
    "callbacks = PyTorchCallbacks(\n",
    "    model=model,\n",
    "    best_weights_path=best_weights_path,\n",
    "    log_path=log_path,\n",
    "    monitor=monitor,\n",
    "    patience=es_patience\n",
    ")\n",
    "\n",
    "# Loop de entrenamiento\n",
    "for epoch in range(epochs):\n",
    "    # Entrenamiento\n",
    "    model.train()\n",
    "    train_loss, train_acc = train_epoch(model, train_dataloader, optimizer, criterion)\n",
    "    \n",
    "    # Validación\n",
    "    model.eval()\n",
    "    val_loss, val_acc = validate_epoch(model, test_dataloader, criterion)\n",
    "    \n",
    "    # Callbacks\n",
    "    current_metric = val_loss if monitor == 'val_loss' else val_acc\n",
    "    callbacks.on_epoch_end(current_metric, epoch)\n",
    "    callbacks.log_metrics(epoch, train_loss, val_loss, train_acc, val_acc)\n",
    "    \n",
    "    # Verificar early stopping\n",
    "    if callbacks.should_stop():\n",
    "        break\n",
    "\n",
    "callbacks.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86575df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosquitosClasificacion (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
