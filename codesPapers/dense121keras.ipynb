{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3993e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "### DenseNet121 N_FFT 256 - 23 EPOCHS - 0.96 ACC ON 20% TEST\n",
    "\n",
    "##############################################################################\n",
    "import os, math\n",
    "import numpy as np\n",
    "seed = 2018\n",
    "np.random.seed(seed)\n",
    "\n",
    "import librosa\n",
    "from scipy import signal\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "from keras import Model\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    " \n",
    "from keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.nasnet import NASNetLarge, NASNetMobile\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.xception import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90dc1ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = DenseNet121\n",
    "#current_model = DenseNet169\n",
    "#current_model = DenseNet201\n",
    "#current_model = InceptionResNetV2\n",
    "#current_model = InceptionV3\n",
    "#current_model = MobileNet\n",
    "#current_model = NASNetLarge\n",
    "#current_model = NASNetMobile\n",
    "#current_model = VGG16\n",
    "#current_model = VGG19\n",
    "#current_model = Xception\n",
    "\n",
    "model_name = 'wingbeats_' + current_model.__name__\n",
    "\n",
    "best_weights_path = model_name + '.weights.h5'\n",
    "log_path = model_name + '.log'\n",
    "monitor = 'val_acc'\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "es_patience = 7\n",
    "rlr_patience = 3\n",
    "\n",
    "SR = 8000\n",
    "N_FFT = 256\n",
    "HOP_LEN = N_FFT // 6\n",
    "input_shape = (129, 120, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa4c3739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ae. aegypti #recs =  85553\n",
      "Ae. albopictus #recs =  20231\n",
      "An. gambiae #recs =  49471\n",
      "An. arabiensis #recs =  19297\n",
      "C. pipiens #recs =  30415\n",
      "C. quinquefasciatus #recs =  74599\n",
      "total #recs =  279566\n",
      "train #recs =  223652\n",
      "test #recs =  55914\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Ae. aegypti', 'Ae. albopictus', 'An. gambiae', 'An. arabiensis', 'C. pipiens', 'C. quinquefasciatus']\n",
    "\n",
    "X_names = []\n",
    "y = []\n",
    "target_count = []\n",
    "\n",
    "for i, target in enumerate(target_names):\n",
    "    target_count.append(0)\n",
    "    path = './Wingbeats/' + target + '/'\n",
    "    for [root, dirs, files] in os.walk(path, topdown = False):\n",
    "        for filename in files:\n",
    "            name,ext = os.path.splitext(filename)\n",
    "            if ext == '.wav':\n",
    "                name = os.path.join(root, filename)\n",
    "                y.append(i)\n",
    "                X_names.append(name)\n",
    "                target_count[i]+=1\n",
    "                # if target_count[i] > 20000:\n",
    "                #     break\n",
    "    print (target, '#recs = ', target_count[i])\n",
    "\n",
    "print ('total #recs = ', len(y))\n",
    "\n",
    "X_names, y = shuffle(X_names, y, random_state = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_names, y, stratify = y, test_size = 0.20, random_state = seed)\n",
    "\n",
    "print ('train #recs = ', len(X_train))\n",
    "print ('test #recs = ', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27783b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import apply_affine_transform\n",
    "\n",
    "def shift(x, wshift, hshift, fill_mode='constant', cval=0.):\n",
    "    \"\"\"Desplaza una imagen ajustando automáticamente los ejes\"\"\"\n",
    "    print(f\"Forma de la imagen: {x.shape}\")  # Para debug\n",
    "    \n",
    "    # Determinar automáticamente los ejes basado en la forma\n",
    "    if len(x.shape) == 2:  # (alto, ancho)\n",
    "        # Imagen en escala de grises sin canal\n",
    "        row_axis, col_axis, channel_axis = 0, 1, None\n",
    "    elif len(x.shape) == 3:  # (alto, ancho, canales) o (canales, alto, ancho)\n",
    "        if x.shape[0] in [1, 3]:  # (canales, alto, ancho)\n",
    "            row_axis, col_axis, channel_axis = 1, 2, 0\n",
    "        else:  # (alto, ancho, canales)\n",
    "            row_axis, col_axis, channel_axis = 0, 1, 2\n",
    "    else:\n",
    "        raise ValueError(f\"Forma de imagen no soportada: {x.shape}\")\n",
    "    \n",
    "    print(f\"Ejes detectados - row: {row_axis}, col: {col_axis}, channel: {channel_axis}\")\n",
    "    \n",
    "    tx = wshift * x.shape[col_axis]\n",
    "    ty = hshift * x.shape[row_axis]\n",
    "    \n",
    "    if channel_axis is not None:\n",
    "        x = apply_affine_transform(\n",
    "            x, \n",
    "            tx=tx, \n",
    "            ty=ty, \n",
    "            channel_axis=channel_axis, \n",
    "            fill_mode=fill_mode, \n",
    "            cval=cval\n",
    "        )\n",
    "    else:\n",
    "        # Para imágenes sin canal de color\n",
    "        x = apply_affine_transform(\n",
    "            x, \n",
    "            tx=tx, \n",
    "            ty=ty, \n",
    "            fill_mode=fill_mode, \n",
    "            cval=cval\n",
    "        )\n",
    "    \n",
    "    return x\n",
    "def random_data_shift(data, w_limit = (-0.25, 0.25), h_limit = (-0.0, 0.0), cval = 0., u = 0.5):\n",
    "    if np.random.random() < u:\n",
    "        wshift = np.random.uniform(w_limit[0], w_limit[1])\n",
    "        hshift = np.random.uniform(h_limit[0], h_limit[1])\n",
    "        data = shift(data, wshift, hshift, cval = cval)\n",
    "    return data\n",
    "\n",
    "# def random_data_shift(data, u = 0.5):\n",
    "#     if np.random.random() < u:\n",
    "#         data = np.roll(data, int(round(np.random.uniform(-(len(data)), (len(data))))))\n",
    "#     return data\n",
    "\n",
    "def train_generator():\n",
    "    while True:\n",
    "        for start in range(0, len(X_train), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            \n",
    "            end = min(start + batch_size, len(X_train))\n",
    "            train_batch = X_train[start:end]\n",
    "            labels_batch = y_train[start:end]\n",
    "            \n",
    "            for i in range(len(train_batch)):\n",
    "                data, rate = librosa.load(train_batch[i], sr = SR)\n",
    "\n",
    "                #data = random_data_shift(data, u = 1.0)\n",
    "\n",
    "                data = librosa.stft(data, n_fft = N_FFT, hop_length = HOP_LEN)\n",
    "                data = librosa.amplitude_to_db(data)\n",
    "\n",
    "                data = np.flipud(data)\n",
    "\n",
    "                data = np.expand_dims(data, axis = -1)\n",
    "                data = random_data_shift(data, w_limit = (-0.25, 0.25), h_limit = (-0.0, 0.0), cval = np.min(data), u = 1.0)\n",
    "\n",
    "                # data = np.squeeze(data, axis = -1)\n",
    "                # plt.imshow(data, cmap = 'gray')\n",
    "                # plt.show()\n",
    "                # data = np.expand_dims(data, axis = -1)\n",
    "\n",
    "                x_batch.append(data)\n",
    "                y_batch.append(labels_batch[i])\n",
    "\n",
    "            x_batch = np.array(x_batch, np.float32)\n",
    "            y_batch = np.array(y_batch, np.float32)\n",
    "            \n",
    "            y_batch = to_categorical(y_batch, len(target_names))\n",
    "            \n",
    "            yield x_batch, y_batch\n",
    "\n",
    "def valid_generator():\n",
    "    while True:\n",
    "        for start in range(0, len(X_test), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            \n",
    "            end = min(start + batch_size, len(X_test))\n",
    "            test_batch = X_test[start:end]\n",
    "            labels_batch = y_test[start:end]\n",
    "            \n",
    "            for i in range(len(test_batch)):\n",
    "                data, rate = librosa.load(test_batch[i], sr = SR)\n",
    "\n",
    "                data = librosa.stft(data, n_fft = N_FFT, hop_length = HOP_LEN)\n",
    "                data = librosa.amplitude_to_db(data)\n",
    "\n",
    "                data = np.flipud(data)\n",
    "\n",
    "                data = np.expand_dims(data, axis = -1)\n",
    "\n",
    "                x_batch.append(data)\n",
    "                y_batch.append(labels_batch[i])\n",
    "\n",
    "            x_batch = np.array(x_batch, np.float32)\n",
    "            y_batch = np.array(y_batch, np.float32)\n",
    "            \n",
    "            y_batch = to_categorical(y_batch, len(target_names))\n",
    "            \n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28a141d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de la imagen: (129, 120, 1)\n",
      "Ejes detectados - row: 0, col: 1, channel: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2943272/3682913099.py:72: UserWarning: amplitude_to_db was called on complex input so phase information will be discarded. To suppress this warning, call amplitude_to_db(np.abs(S)) instead.\n",
      "  data = librosa.amplitude_to_db(data)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'row_axis', 'col_axis', and 'channel_axis' must be distinct",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      5\u001b[39m model.compile(optimizer = \u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, loss = \u001b[33m'\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m, metrics = [\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])  \n\u001b[32m      7\u001b[39m callbacks_list = [ModelCheckpoint(monitor = monitor,\n\u001b[32m      8\u001b[39m                                 filepath = best_weights_path, \n\u001b[32m      9\u001b[39m                                 save_best_only = \u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m                     CSVLogger(filename = log_path)]\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mceil\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mceil\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m model.load_weights(best_weights_path)\n\u001b[32m     28\u001b[39m loss, acc = model.evaluate_generator(valid_generator(),\n\u001b[32m     29\u001b[39m         steps = \u001b[38;5;28mint\u001b[39m(math.ceil(\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_test)) / \u001b[38;5;28mfloat\u001b[39m(batch_size))))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Proyectos/MosquitosMariko/mosquitosClasificacion/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mtrain_generator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     74\u001b[39m data = np.flipud(data)\n\u001b[32m     76\u001b[39m data = np.expand_dims(data, axis = -\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m data = \u001b[43mrandom_data_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_limit\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.25\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_limit\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# data = np.squeeze(data, axis = -1)\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# plt.imshow(data, cmap = 'gray')\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# data = np.expand_dims(data, axis = -1)\u001b[39;00m\n\u001b[32m     84\u001b[39m x_batch.append(data)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mrandom_data_shift\u001b[39m\u001b[34m(data, w_limit, h_limit, cval, u)\u001b[39m\n\u001b[32m     46\u001b[39m     wshift = np.random.uniform(w_limit[\u001b[32m0\u001b[39m], w_limit[\u001b[32m1\u001b[39m])\n\u001b[32m     47\u001b[39m     hshift = np.random.uniform(h_limit[\u001b[32m0\u001b[39m], h_limit[\u001b[32m1\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     data = \u001b[43mshift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwshift\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhshift\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mshift\u001b[39m\u001b[34m(x, wshift, hshift, fill_mode, cval)\u001b[39m\n\u001b[32m     22\u001b[39m ty = hshift * x.shape[row_axis]\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m channel_axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     x = \u001b[43mapply_affine_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfill_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcval\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# Para imágenes sin canal de color\u001b[39;00m\n\u001b[32m     35\u001b[39m     x = apply_affine_transform(\n\u001b[32m     36\u001b[39m         x, \n\u001b[32m     37\u001b[39m         tx=tx, \n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m         cval=cval\n\u001b[32m     41\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: 'row_axis', 'col_axis', and 'channel_axis' must be distinct"
     ]
    }
   ],
   "source": [
    "img_input = Input(shape = input_shape)\n",
    "\n",
    "model = current_model(input_tensor = img_input, classes = len(target_names), weights = None)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])  \n",
    "\n",
    "callbacks_list = [ModelCheckpoint(monitor = monitor,\n",
    "                                filepath = best_weights_path, \n",
    "                                save_best_only = True, \n",
    "                                save_weights_only = True,\n",
    "                                verbose = 1), \n",
    "                    EarlyStopping(monitor = monitor,\n",
    "                                patience = es_patience, \n",
    "                                verbose = 1),\n",
    "\n",
    "                    CSVLogger(filename = log_path)]\n",
    "\n",
    "model.fit(train_generator(),\n",
    "    steps_per_epoch = int(math.ceil(float(len(X_train)) / float(batch_size))),\n",
    "    validation_data = valid_generator(),\n",
    "    validation_steps = int(math.ceil(float(len(X_test)) / float(batch_size))),\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks_list,\n",
    "    shuffle = False)\n",
    "\n",
    "model.load_weights(best_weights_path)\n",
    "\n",
    "loss, acc = model.evaluate_generator(valid_generator(),\n",
    "        steps = int(math.ceil(float(len(X_test)) / float(batch_size))))\n",
    "\n",
    "#print('loss:', loss)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosquitosClasificacion (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
